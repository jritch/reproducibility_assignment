---
title: "Reproducibility Report"
output:
  html_document:
    toc: true
    toc_float: true
---

[TEXT IN SQUARE BRACKETS IS HERE FOR GUIDANCE. PLEASE DELETE TEXT IN SQUARE BRACKETS BEFORE KNITTING THE FINAL REPORT]

# Report Details

[PILOT/COPILOT ENTER RELEVANT REPORT DETAILS HERE]

```{r}
articleID <- '2-10-2014' # insert the article ID code here e.g., "10-3-2015"
reportType <- 'pilot' # specify whether this is the 'pilot' report or 'copilot' report
pilotNames <- 'Jacob William Keith Ritchie' # insert the pilot's name here e.g., "Tom Hardwicke".
copilotNames <- 'Jackie Yang' # # insert the co-pilot's name here e.g., "Michael Frank".
pilotTTC <- 180  # insert the pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
copilotTTC <- 20 # insert the co-pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
pilotStartDate <- as.Date("11/06/19", format = "%m/%d/%y")   # insert the piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
copilotStartDate <- as.Date("11/07/19", format = "%m/%d/%y") # insert the co-piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
completionDate <- as.Date("11/07/19", format = "%m/%d/%y") # insert the date of final report completion in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
```

------

#### Methods summary: 

This study uses a time capsule methodology. Undergraduate students answered questions describing their current experiences (social events, a question from a recent exam, a conversation) and were asked to predict how curious they would be about these experiences and how interesting they would find them (broken down into three dimensions: surprising, meaningful and interesting). Then, 3 months later they reviewed their responses and rated how curious they actually were about their answers, and how interesting they actually found them.

------

#### Target outcomes: 

For this article you should focus on the findings reported in the results section for Study 1 (and Table 1).

Specifically, you should attempt to reproduce all descriptive and inferential analyses reported in the text below and associated tables/figures:

> Table 1 provides descriptive statistics for each measure
for Study 1.

> Participantsâ€™ Time 1 predictions of their curiosity (M = 3.99, SD = 1.32) were lower than their actual curiosity ratings at Time 2, immediately before reading their responses (M = 4.34, SD = 1.25), t(105) = 2.88, p = .005, d = 0.27. Participants also underestimated how interesting they would find their responses. Predictions of interest at Time 1 (M = 3.54, SD = 1.01) were lower than ratings of actual interest experienced at Time 2 (M = 3.82, SD = 0.89), t(105) = 3.10, p = .003, d = 0.29.

**Note**
Make sure to use the original article for additional context and information about any necessary pre-processing steps. Also check for additional supplementary materials that may provide supporting documentation for analysis procedures.
------

[PILOT/COPILOT DO NOT CHANGE THE CODE IN THE CHUNK BELOW]  

```{r global_options, include=FALSE}
# sets up some formatting options for the R Markdown document
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```

# Step 1: Load packages and prepare report object

[PILOT/COPILOT Some useful packages are being loaded below. You can add any additional ones you might need too.]

```{r}
# load packages
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(ReproReports) # custom reporting functions
library(broom)
library(bootES)
library(effsize)
```

[PILOT/COPILOT DO NOT MAKE CHANGES TO THE CODE CHUNK BELOW]

```{r}
# Prepare report object. This will be updated automatically by the reproCheck function each time values are compared
reportObject <- data.frame(dummyRow = TRUE, reportedValue = NA, obtainedValue = NA, valueType = NA, percentageError = NA, comparisonOutcome = NA, eyeballCheck = NA)
```

# Step 2: Load data

```{r}
data = read_sav("../data/Study1_Data.sav")
```

# Step 3: Tidy data

```{r}

data$id <- seq.int(nrow(data)) 

tidy_data <- data %>% 
  filter(T2_Finished == 1) %>% 
  select("id", contains("Interesting"), contains("Curious"), contains("Meaningful"), contains("Surprised"), -contains("diff"), -c("T1_Interesting", "T2_Interesting","T1_Curious", "T2_Curious","T1_Meaningful", "T2_Meaningful","T1_Surprised", "T2_Surprised")) %>%
  gather(measurement,score, -"id") %>% 
  mutate(time = sub("(.*)_.*_.*","\\1", measurement),
         item = sub(".*_(.*)_.*","\\1", measurement),
         measure = tolower(sub(".*_.*_(.*)","\\1", measurement)), # case is inconsistent, so make all lowercase
         interest_measure = factor(measure != "curious", , labels = c("curious", "interesting"))) 
```

# Step 4: Run analysis

## Pre-processing

```{r}

aggregated_data = tidy_data %>%  group_by(id,time,interest_measure) %>% 
  summarise(avg_score = mean(score, na.rm = T)) %>% 
  spread(time,avg_score) %>%
  mutate(diff = (T2 - T1)) %>%
  group_by(interest_measure)  

curious_data <- aggregated_data %>% filter(interest_measure == "curious")

interesting_data <- aggregated_data %>% filter(interest_measure == "interesting")

un_aggregated_data = tidy_data %>%  group_by(id,time,measure) %>% 
  summarise(avg_score = mean(score, na.rm = T)) %>% 
  spread(time,avg_score) %>%
  mutate(diff = (T2 - T1)) %>%
  group_by(measure) 
  
surprising_data <- un_aggregated_data %>% filter(measure == "surprised")
meaningful_data <- un_aggregated_data %>% filter(measure == "meaningful")
un_aggregated_interesting_data <- un_aggregated_data %>% filter(measure == "interesting")

```

## Descriptive statistics

```{r}

boot_results = bootES(curious_data, R=10000, data.col="T1")
reproCheck('3.99', boot_results$t0, valueType="mean")
reproCheck('3.74', boot_results$bounds[1], valueType="ci")
reproCheck('4.24', boot_results$bounds[2], valueType="ci")

boot_results = bootES(curious_data, R=10000, data.col="T2")
reproCheck('4.34', boot_results$t0, valueType="mean")
reproCheck('4.10', boot_results$bounds[1], valueType="ci")
reproCheck('4.58', boot_results$bounds[2], valueType="ci")

boot_results = bootES(curious_data, R=10000, data.col="diff")
reproCheck('0.35', boot_results$t0, valueType="mean")
reproCheck('0.11', boot_results$bounds[1], valueType="ci")
reproCheck('0.59', boot_results$bounds[2], valueType="ci")

std_dev = sd(curious_data$T1)
reproCheck('1.32', std_dev, valueType="sd")
std_dev = sd(curious_data$T2)
reproCheck('1.25', std_dev, valueType="sd")

cohen_d = cohen.d(curious_data$T2,curious_data$T1)
reproCheck('0.27', cohen_d$estimate, valueType="d")

boot_results = bootES(interesting_data, R=10000, data.col="T1")
reproCheck('3.54', boot_results$t0, valueType="mean")
reproCheck('3.34', boot_results$bounds[1], valueType="ci")
reproCheck('3.73', boot_results$bounds[2], valueType="ci")

boot_results = bootES(interesting_data, R=10000, data.col="T2")
reproCheck('3.82', boot_results$t0, valueType="mean")
reproCheck('3.65', boot_results$bounds[1], valueType="ci")
reproCheck('4.00', boot_results$bounds[2], valueType="ci")

boot_results = bootES(interesting_data, R=10000, data.col="diff")
reproCheck('0.29', boot_results$t0, valueType="mean")
reproCheck('0.10', boot_results$bounds[1], valueType="ci")
reproCheck('0.47', boot_results$bounds[2], valueType="ci")

std_dev = sd(interesting_data$T1)
reproCheck('1.01', std_dev, valueType="sd")
std_dev = sd(interesting_data$T2)
reproCheck('0.89', std_dev, valueType="sd")

cohen_d = cohen.d(interesting_data$T2,interesting_data$T1)
reproCheck('0.29', cohen_d$estimate, valueType="d")

boot_results = bootES(surprising_data, R=10000, data.col="T1")
reproCheck('2.84', boot_results$t0, valueType="mean")
reproCheck('2.64', boot_results$bounds[1], valueType="ci")
reproCheck('3.05', boot_results$bounds[2], valueType="ci")

boot_results = bootES(surprising_data, R=10000, data.col="T2")
reproCheck('3.25', boot_results$t0, valueType="mean")
reproCheck('3.06', boot_results$bounds[1], valueType="ci")
reproCheck('3.44', boot_results$bounds[2], valueType="ci")

boot_results = bootES(surprising_data, R=10000, data.col="diff")
reproCheck('0.40', boot_results$t0, valueType="mean")
reproCheck('0.19', boot_results$bounds[1], valueType="ci")
reproCheck('0.62', boot_results$bounds[2], valueType="ci")

boot_results = bootES(meaningful_data, R=10000, data.col="T1")
reproCheck('3.81', boot_results$t0, valueType="mean")
reproCheck('3.60', boot_results$bounds[1], valueType="ci")
reproCheck('4.03', boot_results$bounds[2], valueType="ci")

boot_results = bootES(meaningful_data, R=10000, data.col="T2")
reproCheck('4.04', boot_results$t0, valueType="mean")
reproCheck('3.84', boot_results$bounds[1], valueType="ci")
reproCheck('4.23', boot_results$bounds[2], valueType="ci")

boot_results = bootES(meaningful_data, R=10000, data.col="diff")
reproCheck('0.22', boot_results$t0, valueType="mean")
reproCheck('0.03', boot_results$bounds[1], valueType="ci")
reproCheck('0.42', boot_results$bounds[2], valueType="ci")

boot_results = bootES(un_aggregated_interesting_data, R=10000, data.col="T1")
reproCheck('3.95', boot_results$t0, valueType="mean")
reproCheck('3.73', boot_results$bounds[1], valueType="ci")
reproCheck('4.18', boot_results$bounds[2], valueType="ci")

boot_results = bootES(un_aggregated_interesting_data, R=10000, data.col="T2")
reproCheck('4.19', boot_results$t0, valueType="mean")
reproCheck('4.00', boot_results$bounds[1], valueType="ci")
reproCheck('4.38', boot_results$bounds[2], valueType="ci")

boot_results = bootES(un_aggregated_interesting_data, R=10000, data.col="diff")
reproCheck('0.23', boot_results$t0, valueType="mean")
reproCheck('0.02', boot_results$bounds[1], valueType="ci")
reproCheck('0.45', boot_results$bounds[2], valueType="ci")

```

## Inferential statistics

```{r}

t_test_results <- t.test(curious_data$T2,curious_data$T1,paired = T)
reproCheck(".005",t_test_results$p.value,valueType = 'p')
reproCheck("2.88", t_test_results$statistic, valueType = 't')

t_test_results <- t.test(interesting_data$T2,interesting_data$T1,paired = T)
reproCheck(".003",t_test_results$p.value,valueType = 'p')
reproCheck("3.10", t_test_results$statistic, valueType = 't')

t_test_results <- t.test(surprising_data$T2,surprising_data$T1,paired = T)
reproCheck("P < 0.001",t_test_results$p.value,valueType = 'p',eyeballCheck = T)

t_test_results <- t.test(meaningful_data$T2,meaningful_data$T1,paired = T)
reproCheck(".02",t_test_results$p.value,valueType = 'p')

t_test_results <- t.test(un_aggregated_interesting_data$T2,un_aggregated_interesting_data$T1,paired = T)
reproCheck(".03",t_test_results$p.value,valueType = 'p')


```

# Step 5: Conclusion

It was successful! The errors in the Bootstrapped 95% CIs are very small (about the same size as the variation between different runs). There is also a small rounding error in p value.

[PILOT/COPILOT DOD NOT EDIT THE CODE CHUNK BELOW]

```{r}
reportObject <- reportObject %>%
  filter(dummyRow == FALSE) %>% # remove the dummy row
  select(-dummyRow) %>% # remove dummy row designation
  mutate(articleID = articleID) %>% # add variables to report 
  select(articleID, everything()) # make articleID first column

# decide on final outcome
if(any(reportObject$comparisonOutcome %in% c("MAJOR_ERROR", "DECISION_ERROR"))){
  finalOutcome <- "Failure"
}else{
  finalOutcome <- "Success"
}

# collate report extra details
reportExtras <- data.frame(articleID, pilotNames, copilotNames, pilotTTC, copilotTTC, pilotStartDate, copilotStartDate, completionDate, finalOutcome)

# save report objects
if(reportType == "pilot"){
  write_csv(reportObject, "pilotReportDetailed.csv")
  write_csv(reportExtras, "pilotReportExtras.csv")
}

if(reportType == "copilot"){
  write_csv(reportObject, "copilotReportDetailed.csv")
  write_csv(reportExtras, "copilotReportExtras.csv")
}
```

# Session information

[This function will output information about the package versions used in this report:]

```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```
